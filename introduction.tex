%% introduction.tex - introduction and motivation for the work
%%
%% Copyright 2010, 2011, 2012, 2014, 2015 Jeffrey Finkelstein.
%%
%% This LaTeX markup document is made available under the terms of the Creative
%% Commons Attribution-ShareAlike 4.0 International License,
%% https://creativecommons.org/licenses/by-sa/4.0/.
\section{Introduction}
% Foreword
%
% context (focus on anyone) why now? - current situation, and why the need is so important
Our main tool for comparing relative difficulties of computational problems is the many-one reduction, an encoding of an instance of one problem as an instance of another.
% need (focus on readers) why you? - why this is relevant to the reader, and why something needed to be done
Reductions involving problems of equivalence like the graph isomorphism problem have access to both elements of the pair simultaneously.
However, a more natural notion of reduction between problems of equivalence requires the reduction to access each element of the pair separately, and indeed, to the best of our knowledge, every many-one reduction between problems of equivalence behaves this way.

%%% relevant existing work, given as part of the need
The \emph{kernel reduction}, defined in \autocite[Definition~4.13]{fg11}, formally captures this notion of reduction among computational problems of equivalence involving independent transformation of each element of a pair.
This type of reduction has appeared not only in complexity theory but also in computability theory and mathematical logic under names such as ``Borel reduction'' \autocite{fs89}, ``strong isomorphism reduction'' \autocite{bcffm}, and ``functorial reduction'' \autocite{babai14, babai77, kucera76, zkt85}, among many others.
What are the limitations of these types of reductions?

% task (focus on author) why me? - what was undertaken to address the need
We undertake a thorough investigation of the basic properties of kernel reductions, comparing them with the basic properties of many-one reductions.
% object (focus on document) why this document - what the document covers
%% The starting point for understanding many-one reductions is $\P$ and $\NP$, so we attempt to extend the definition from \autocite{fg11} of $\PEq$, the class of equivalence problems decidable in polynomial time, to the definition of the complexity class $\NPEq$ (\autoref{sec:definitions}).
We determine the limitations of kernel reductions; these appear to be combinatorial, not computational, in nature (\autoref{sec:limitations}).
We discover sufficient conditions for complete problems under kernel reductions in classes of equivalence problems (\autoref{sec:generalcompleteness}).
We compare the new notion of completeness under kernel reductions with the usual notion of completeness under many-one reductions (\autoref{sec:npeqcompleteness}).
Finally, we prove, under the assumption that $\P \neq \NP$, the existence of $\NPEq$-intermediary problems with respect to kernel reductions (\autoref{sec:intermediary}).

% Summary
%
% findings (focus on author) what? - what the work revealed when performing the task
We find that kernel reductions are essentially similar to many-one reductions, but differ in some key aspects.
Like many-one reductions, kernel reductions are transitive and have good closure properties.
The class of equivalence problems in $\PSPACE$ has a complete problem under kernel reductions (\autoref{cor:hardproblems}).
The equivalence of the two equalities $\P = \NP$ and $\PEq = \NPEq$ (\autoref{thm:pnppeqnpeq}) can be proven using the similarity between many-one and kernel reductions.
Just as many-one reductions allow the existence of $\NP$-intermediary problems, kernel reductions allow for the possibility of $\NPEq$-intermediary problems (\autoref{thm:intermediary}).
On the other hand, there are equivalence relations between which there is a many-one reduction but no kernel reduction (\autoref{thm:different}).
Specifically, if there are more equivalence classes, up to strings of certain lengths, in one equivalence relation than in the other, then no kernel reduction can exist.
Finally, under some assumptions, there is an equivalence problem that is not complete for $\NPEq$ under injective kernel reductions (\autoref{thm:inj}), whereas nearly every known $\NP$-complete problem is isomorphic (the Berman--Hartmanis conjecture \autocite{bh77} states that \emph{every} $\NP$-complete problem is isomorphic).

% conclusion (focus on readers) so what? - what the findings mean for the audience
The techniques used in this paper to show that kernel reductions are weaker than many-one reductions are combinatorial (for example, comparing the numbers of equivalence classes).
Combining these with other complexity theoretic and algebraic techniques has already proven useful: there is no polynomial-time kernel reduction from the graph isomorphism problem to the isomorphism problem for strongly regular graphs \autocite[Theorem~22]{babai14}.
This is interesting because even though the latter appears to be a difficult problem, no polynomial-time many-one reduction from the former to the latter is expected to exist \autocite{babai14}, and the lack of a kernel reduction is evidence in that direction.

% perspective (focus on anyone) what now? - what should be done next
Besides the open problems listed in \autoref{sec:generalcompleteness}, here are several interesting questions we have not examined.
What do problems of \emph{inequivalence} (see \autocite{gj79} for some examples) have to do with completeness under kernel reductions?
When can we translate a proof that an equivalence relation is complete under many-one reductions (see \autocite[Theorem~1]{rs11} for a recent example) to a proof that it is complete under kernel reductions?
When is the problem of computing the size of an equivalence class Turing-equivalent to deciding equivalence (see \autocite[Theorem~1.24]{kst93} for an example of such an equivalence for graph isomorphism).
