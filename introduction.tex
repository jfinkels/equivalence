%% introduction.tex - introduction and motivation for the work
%%
%% Copyright 2010, 2011, 2012, 2014 Jeffrey Finkelstein.
%%
%% This LaTeX markup document is made available under the terms of the Creative
%% Commons Attribution-ShareAlike 4.0 International License,
%% https://creativecommons.org/licenses/by-sa/4.0/.
\section{Introduction}

\todo{Add citations to all the recent work on uncomputable equivalence relations.}

In this paper we examine the power of ``kernel reductions'' on languages induced by equivalence relations, specifically for which membership can be decided by a non-deterministic Turing machine running in time polynomial in the length of the input.
Given two equivalence relations $R$ and $S$, each of which can be expressed as a set of pairs of strings, a \defn{kernel reduction} from $R$ to $S$ is a function $f$ for which $\pair{x}{y}\in R\iff\pair{f(x)}{f(y)}\in S$.
This function maps each \emph{member} of the pair in $R$ to an element of a pair in the relation $S$, instead of mapping the \emph{entire} pair to another pair.
The full definition of ``kernel reduction'' is given by Fortnow and Grochow \autocite{fg11} (and is repeated below), though the idea has existed before then.
In fact, all polynomial time many-one reductions to and from the graph isomorphism problem are, to the best of our knowledge, in fact kernel reductions, though they have not before been called by this name.
The same seems to go for polynomial time many-one reductions to and from other equivalence problems.
This kind of reduction is more natural than the usual many-one reduction for problems of equivalence.
It is therefore important to study the power of these reductions and how they can help further classify currently known and newly discovered complexity classes.

We would briefly like to point out that \autocite{bcffm} provides a thorough treatment of the kernel reduction (from the viewpoint of a logician), there called a ``strong isomorphism reduction'', and this work extends and clarifies several of the results from that paper (from the viewpoint of a complexity theorist).
We have attempted to provide plentiful explicit references to specific theorems in that work where appropriate and we encourage the reader to examine the original theorems and proofs.

In \autoref{sec:preliminaries} we provide the definitions necessary for the study of polynomial time kernel reductions and effectively computable equivalence problems.
In \autoref{sec:definitions} we provide some possible definitions for $\NPEq$, the class of equivalence problems for which membership can be decided in nondeterministic polynomial time.

In the next three sections we see a common thread among some of the results.
The results show that the number of equivalence classes in an equivalence relation is important in determining if reductions to and from it are possible.
In \autoref{sec:limitations} we show that polynomial time many-one reductions are strictly more powerful than polynomial time many-one reductions.
In \autoref{sec:generalcompleteness} we provide general sufficient conditions under which a complexity class consisting of equivalence relations contains a problem which is hard under polynomial time kernel reductions.
In \autoref{sec:npeqcompleteness} we explore the relationship between completeness in $\NP$ under polynomial time many-one reductions and completeness in $\NPEq$ under polynomial time kernel reductions.

In \autoref{sec:intermediary} we adapt a proof by Sch\"{o}ning's ``uniform diagonalization theorem'' to the setting of equivalence relations and polynomial time kernel reductions in order to prove results about intermediary problems.
In \autoref{sec:openproblems} we provide a few open problems, although many open problems are posed throughout this work.
