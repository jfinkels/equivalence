%% conclusion.tex - findings and conclusion of the work
%%
%% Copyright 2010, 2011, 2012, 2014, 2015 Jeffrey Finkelstein.
%%
%% This LaTeX markup document is made available under the terms of the Creative
%% Commons Attribution-ShareAlike 4.0 International License,
%% https://creativecommons.org/licenses/by-sa/4.0/.
\section{Conclusion}
% Summary
%
% findings (focus on author) what? - what the work revealed when performing the task
Throughout this work we have proven that kernel reductions are similar to many-one reductions in the most basic ways, but differ in some key aspects.
Like many-one reductions, kernel reductions are transitive and have good closure properties.
The class of equivalence problems in $\PSPACE$ has a complete problem under kernel reductions (\autoref{cor:hardproblems}).
The equivalence of the two equalities $\P = \NP$ and $\PEq = \NPEq$ (\autoref{thm:pnppeqnpeq}) uses the similarity between many-one and kernel reductions.
Just as many-one reductions allow the existence of $\NP$-intermediary problems, kernel reductions allow for the possibility of $\NPEq$-intermediary problems (\autoref{thm:intermediary}).
On the other hand, there are equivalence relations between which there is a many-one reduction but no kernel reduction (\autoref{thm:different}).
Specifically, if there are more equivalence classes, up to strings of certain lengths, in $R$ than in $S$, then no kernel reduction can exist.
Finally, under some assumptions, there is an equivalence problem that is not complete for $\NPEq$ under injective kernel reductions (\autoref{thm:inj}), whereas nearly every known $\NP$-complete problem is isomorphic (the Berman--Hartmanis conjecture \autocite{bh77} states that \emph{every} $\NP$-complete problem is isomorphic).

% conclusion (focus on readers) so what? - what the findings mean for the audience
The techniques used in this paper to show that kernel reductions are weaker than many-one reductions are combinatorial techniques (for example, comparing the numbers of equivalence classes).
Combining these with other complexity theoretic and algebraic techniques has already proven useful: there is no polynomial-time kernel reduction from the graph isomorphism problem to the isomorphism problem for strongly regular graphs \autocite[Theorem~22]{babai14}.
This is interesting because even though the latter appears to be a difficult problem, no polynomial-time many-one reduction from the former to the latter is expected to exist \autocite{babai14}, and the lack of a kernel reduction is evidence in that direction.

% perspective (focus on anyone) what now? - what should be done next
Besides the open problems listed in \autoref{sec:generalcompleteness}, we consider the following questions to be worth exploring.
First, there are several problems of \emph{inequivalence} in \autocite{gj79} listed as $\NP$-complete or as $\PSPACE$-complete.
What do these problems have to do with $\NPEq$-completeness, $\coNPEq$-completeness, and $\PSPACEEq$-completeness?
Second, when can results like \autocite[Theorem~1]{rs11}, for example, which shows that an equivalence relation is complete for $\L$ under many-one reductions via a reduction from a problem that is \emph{not} an equivalence relation, be translated to a proof that the problem is complete under kernel reductions for the corresponding class of equivalence problems?
